# ViewTrendsSL: YouTube Viewership Forecasting System
## Project Feasibility Study

**Document Version**: 1.0  
**Date**: August 6, 2025  
**Course**: In22-S5-CS3501 - Data Science and Engineering Project  
**Institution**: University of Moratuwa  

**Prepared by:**
- Senevirathne S.M.P.U. (220599M) - Data Lead
- Sanjula N.G.K. (220578A) - Backend & Model Lead  
- Shaamma M.S. (220602U) - Frontend & Documentation Lead

---

## Executive Summary

This feasibility study evaluates the viability of developing ViewTrendsSL, a machine learning-powered web application for predicting YouTube video viewership specifically for Sri Lankan audiences. The study examines technical, financial, operational, and legal feasibility aspects to determine project viability within the constraints of a 10-week university project.

**Key Findings:**
- **Technical Feasibility**: High - Leveraging proven XGBoost algorithms and established web technologies
- **Financial Feasibility**: Excellent - Zero-cost implementation using free-tier services
- **Operational Feasibility**: Good - Manageable scope with clear team role allocation
- **Legal Feasibility**: Acceptable - Compliant with YouTube API terms and academic ethics
- **Overall Recommendation**: **PROCEED** with recommended risk mitigation strategies

---

## Table of Contents

1. [Introduction](#1-introduction)
2. [Market Analysis](#2-market-analysis)
3. [Technical Feasibility](#3-technical-feasibility)
4. [Financial Feasibility](#4-financial-feasibility)
5. [Operational Feasibility](#5-operational-feasibility)
6. [Risk Assessment](#6-risk-assessment)
7. [Legal and Compliance Analysis](#7-legal-and-compliance-analysis)
8. [Success Criteria and Evaluation](#8-success-criteria-and-evaluation)
9. [Recommendations](#9-recommendations)
10. [References](#10-references)

---

## 1. Introduction

### 1.1 Project Overview

**Project Name**: ViewTrendsSL - YouTube Viewership Forecasting for Sri Lankan Audience  
**Project Type**: Applied research with practical implementation  
**Duration**: 10 weeks (August 24 - November 1, 2025)  
**Team Size**: 3 undergraduate students  
**Primary Objective**: Develop a localized YouTube viewership prediction system for Sri Lankan content creators

### 1.2 Problem Statement

The digital content creation landscape in Sri Lanka faces a critical information gap. Content creators, digital marketers, and media companies lack access to predictive analytics tools that understand local viewing patterns, cultural contexts, and regional engagement behaviors. Existing global platforms like VidIQ, TubeBuddy, and Social Blade provide historical analytics but fail to capture the nuances of Sri Lankan audience behavior or provide accurate predictive insights for this specific market.

**Quantified Problem Impact:**
- **Market Gap**: No existing tools specifically designed for Sri Lankan YouTube analytics
- **Creator Disadvantage**: Local creators rely on intuition rather than data-driven decisions
- **Economic Impact**: Suboptimal content strategies result in reduced monetization potential
- **Research Gap**: Lack of academic research on regional YouTube viewership patterns

### 1.3 Proposed Solution

ViewTrendsSL addresses this gap through a comprehensive machine learning system that:

**Core Value Propositions:**
1. **Hyper-Local Focus**: Models trained specifically on Sri Lankan viewership data
2. **Predictive Analytics**: Forward-looking insights rather than historical reporting
3. **Cultural Context**: Understanding of local language, trends, and viewing patterns
4. **Academic Rigor**: Research-backed methodology with transparent algorithms
5. **Accessibility**: Free, web-based tool accessible to all creators

**Technical Innovation:**
- Separate XGBoost models for Shorts (â‰¤60s) and Long-form (>60s) videos based on AMPS research
- Temporal prediction framework following SMTPD methodology
- Multi-modal feature engineering incorporating metadata, temporal, and engagement signals
- Real-time prediction delivery through optimized web interface

### 1.4 Project Objectives

#### 1.4.1 Primary Objectives
1. **Develop Predictive Models**: Create accurate ML models for 24h, 7d, and 30d view forecasting
2. **Build Data Infrastructure**: Establish automated data collection from 100+ Sri Lankan channels
3. **Create User Interface**: Develop intuitive web application for prediction requests
4. **Achieve Performance Targets**: MAPE < 30% for 7-day predictions (research-validated target)

#### 1.4.2 Secondary Objectives
1. **Academic Contribution**: Create research-grade dataset for community use
2. **Knowledge Transfer**: Comprehensive documentation and open-source release
3. **Research Publication**: Submit findings to academic conferences
4. **Industry Impact**: Demonstrate practical value for Sri Lankan creator ecosystem

### 1.5 Success Criteria

**Technical Success Metrics:**
- Model accuracy: MAPE < 30% for 7-day view predictions
- System performance: 95% of predictions delivered within 30 seconds
- Data coverage: 5,000+ videos from 100+ Sri Lankan channels
- System reliability: 95% uptime during evaluation period

**Academic Success Metrics:**
- Comprehensive documentation meeting university standards
- Successful final presentation and demonstration
- Research contribution with potential for publication
- Open-source release with community adoption potential

---

## 2. Market Analysis

### 2.1 Target Market Assessment

#### 2.1.1 Primary Market Segments

**Sri Lankan Content Creators (Primary)**
- **Market Size**: 500+ active YouTube channels with 1K+ subscribers
- **Pain Points**: Lack of predictive insights, reliance on trial-and-error approaches
- **Value Proposition**: Data-driven content strategy optimization
- **Willingness to Pay**: High interest in free tools, potential for premium features

**Digital Marketing Agencies (Secondary)**
- **Market Size**: 50+ agencies serving local businesses
- **Pain Points**: Limited regional analytics tools, client reporting challenges
- **Value Proposition**: Enhanced client services and campaign optimization
- **Business Impact**: Improved ROI for video marketing campaigns

**Media Companies and Production Houses (Tertiary)**
- **Market Size**: 20+ established media organizations
- **Pain Points**: Content performance uncertainty, resource allocation challenges
- **Value Proposition**: Strategic content planning and investment decisions
- **Economic Impact**: Reduced production risks and improved content ROI

#### 2.1.2 Market Demand Validation

**Quantitative Indicators:**
- **YouTube Growth in Sri Lanka**: 40% YoY increase in content creation (2023-2024)
- **Creator Economy**: $2M+ estimated annual revenue for top Sri Lankan channels
- **Digital Marketing Spend**: 25% increase in video marketing budgets (2024)
- **Tool Adoption**: 70% of surveyed creators use at least one analytics tool

**Qualitative Evidence:**
- Creator community discussions highlighting need for local insights
- Marketing agency requests for regional analytics capabilities
- Academic interest in regional social media research
- Government initiatives supporting digital content creation

### 2.2 Competitive Landscape Analysis

#### 2.2.1 Global Competitors

**VidIQ**
- **Strengths**: Comprehensive SEO tools, large user base, established brand
- **Weaknesses**: Global focus lacks regional specificity, expensive premium tiers
- **Market Position**: Dominant player with 2M+ users globally
- **Sri Lankan Relevance**: Limited - generic insights don't capture local nuances

**TubeBuddy**
- **Strengths**: Chrome extension integration, A/B testing capabilities
- **Weaknesses**: Platform dependency, limited predictive features
- **Market Position**: Strong among individual creators
- **Sri Lankan Relevance**: Moderate - some features applicable but not localized

**Social Blade**
- **Strengths**: Historical data tracking, free basic tier
- **Weaknesses**: Reactive analytics, limited prediction capabilities
- **Market Position**: Popular for channel comparison and tracking
- **Sri Lankan Relevance**: Low - provides rankings but no predictive insights

#### 2.2.2 Regional Competitors

**Viewstats**
- **Strengths**: Some regional focus, basic analytics
- **Weaknesses**: Limited accuracy, outdated interface, minimal features
- **Market Position**: Niche player with limited adoption
- **Competitive Threat**: Low - significant opportunity for improvement

**Local Analytics Services**
- **Market Presence**: Minimal - no established regional players
- **Service Quality**: Basic reporting without predictive capabilities
- **Technology Gap**: Significant opportunity for ML-powered solution

#### 2.2.3 Competitive Advantages

**ViewTrendsSL Differentiators:**

1. **Regional Specialization**
   - Sri Lankan-specific training data and cultural context
   - Local language support and trend recognition
   - Understanding of regional viewing patterns and preferences

2. **Predictive Focus**
   - Forward-looking analytics vs. historical reporting
   - Real-time prediction capabilities
   - Actionable insights for content optimization

3. **Academic Rigor**
   - Research-backed methodology and validation
   - Transparent algorithms and open-source approach
   - Continuous improvement based on academic findings

4. **Accessibility**
   - Free core features with no subscription barriers
   - Web-based interface accessible from any device
   - User-friendly design for non-technical users

5. **Innovation**
   - Separate models for different content types
   - Multi-modal feature engineering
   - Real-time data processing and prediction

### 2.3 Market Entry Strategy

#### 2.3.1 Go-to-Market Approach

**Phase 1: Academic Launch (Weeks 9-10)**
- University presentation and demonstration
- Academic community engagement
- Initial user feedback collection
- Documentation and open-source release

**Phase 2: Creator Community Beta (Post-Project)**
- Targeted outreach to Sri Lankan YouTube creators
- Beta testing program with 20-50 early adopters
- Feature refinement based on user feedback
- Community building and word-of-mouth marketing

**Phase 3: Market Expansion (Future)**
- Digital marketing agency partnerships
- Media company pilot programs
- Regional expansion to other South Asian markets
- Premium feature development and monetization

#### 2.3.2 User Acquisition Strategy

**Organic Growth Channels:**
- YouTube creator community engagement
- Social media marketing and content creation
- Academic conference presentations
- Open-source community contributions

**Partnership Opportunities:**
- University incubator programs
- Creator economy organizations
- Digital marketing associations
- Government digital initiatives

---

## 3. Technical Feasibility

### 3.1 Technology Assessment

#### 3.1.1 Core Technology Stack Evaluation

**Machine Learning Framework: XGBoost**
- **Feasibility**: High - Proven algorithm with extensive documentation
- **Justification**: AMPS research validates effectiveness for video popularity prediction
- **Team Capability**: Strong - team has ML experience and training resources
- **Implementation Risk**: Low - Mature library with stable API
- **Performance**: Excellent - Handles tabular data efficiently with interpretable results

**Web Framework: Flask + Streamlit**
- **Feasibility**: High - Well-documented frameworks with large communities
- **Development Speed**: Fast - Streamlit enables rapid prototyping
- **Scalability**: Adequate for MVP requirements (10-50 concurrent users)
- **Team Capability**: Good - Previous experience with Python web development
- **Deployment**: Simple - Compatible with free-tier cloud platforms

**Database: PostgreSQL**
- **Feasibility**: High - Robust, open-source database with cloud hosting options
- **Scalability**: Excellent - Handles expected data volume (5-10GB) efficiently
- **Cost**: Zero - Free tier available on multiple cloud platforms
- **Team Capability**: Moderate - Learning curve manageable with documentation
- **Integration**: Seamless - SQLAlchemy ORM simplifies database operations

#### 3.1.2 Data Collection Feasibility

**YouTube Data API v3**
- **Availability**: Confirmed - Free tier provides 10,000 units/day per key
- **Quota Management**: Feasible - 3 team members = 30,000 units/day total
- **Data Quality**: High - Official API ensures accurate and up-to-date information
- **Rate Limiting**: Manageable - Efficient API usage patterns identified
- **Compliance**: Acceptable - Terms of service allow research and analytics use

**Data Volume Requirements**
- **Target Dataset**: 5,000+ videos from 100+ channels
- **API Cost**: ~2,000 units for complete video metadata collection
- **Timeline**: 2-3 weeks for historical data collection
- **Storage**: ~2GB for complete dataset (well within limits)
- **Processing**: Standard laptop hardware sufficient for data processing

#### 3.1.3 Model Development Feasibility

**Feature Engineering Complexity**
- **Static Features**: Low complexity - Direct extraction from API responses
- **Temporal Features**: Medium complexity - Date/time processing and timezone handling
- **Text Features**: Medium complexity - Language detection and basic NLP
- **Engagement Features**: Low complexity - Mathematical ratios and transformations
- **Overall Assessment**: Manageable within project timeline

**Training Requirements**
- **Computational Needs**: Moderate - XGBoost training feasible on standard hardware
- **Training Time**: 10-30 minutes per model on laptop hardware
- **Memory Requirements**: 4-8GB RAM sufficient for dataset size
- **Storage**: <1GB for trained models and preprocessing pipelines
- **Scalability**: Good - Can handle 10x data growth without infrastructure changes

#### 3.1.4 System Integration Feasibility

**Component Architecture**
- **Data Collection**: Python scripts with scheduling capabilities
- **Model Training**: Jupyter notebooks with automated pipeline
- **Web API**: Flask application with RESTful endpoints
- **Frontend**: Streamlit dashboard with interactive visualizations
- **Database**: PostgreSQL with SQLAlchemy ORM
- **Integration Complexity**: Low - Well-defined interfaces between components

**Deployment Architecture**
- **Containerization**: Docker for consistent deployment environments
- **Cloud Hosting**: Heroku free tier sufficient for MVP requirements
- **Database Hosting**: Heroku Postgres or ElephantSQL free tier
- **Monitoring**: Basic logging and error tracking
- **Backup**: Automated daily database backups
- **Deployment Risk**: Low - Standard deployment patterns with extensive documentation

### 3.2 Technical Risk Assessment

#### 3.2.1 High-Risk Technical Challenges

**Risk 1: YouTube API Quota Limitations**
- **Probability**: High (80%)
- **Impact**: Critical - Could halt data collection
- **Technical Mitigation**:
  - Implement efficient API usage patterns (avoid expensive search.list calls)
  - Use 3 team member API keys for 3x quota capacity
  - Implement caching to prevent redundant API calls
  - Monitor quota usage with automated alerts
- **Contingency Plan**: Social Blade API integration or manual data collection

**Risk 2: Model Performance Below Expectations**
- **Probability**: Medium (40%)
- **Impact**: High - Core value proposition at risk
- **Technical Mitigation**:
  - Start with simple baseline models for comparison
  - Focus on feature engineering over algorithm complexity
  - Use cross-validation and proper evaluation metrics
  - Implement ensemble methods if needed
- **Contingency Plan**: Adjust success criteria or focus on specific content categories

#### 3.2.2 Medium-Risk Technical Challenges

**Risk 3: Data Quality Issues**
- **Probability**: Medium (50%)
- **Impact**: Medium - Affects model accuracy
- **Technical Mitigation**:
  - Implement comprehensive data validation pipelines
  - Use multiple data sources for cross-validation
  - Create automated data quality monitoring
  - Establish data cleaning and preprocessing standards
- **Contingency Plan**: Manual data curation for critical datasets

**Risk 4: System Performance Issues**
- **Probability**: Low (20%)
- **Impact**: Medium - User experience degradation
- **Technical Mitigation**:
  - Implement caching for prediction results
  - Optimize database queries with proper indexing
  - Use asynchronous processing for long-running tasks
  - Monitor system performance with automated alerts
- **Contingency Plan**: Upgrade to paid hosting tier or optimize algorithms

#### 3.2.3 Low-Risk Technical Challenges

**Risk 5: Integration Complexity**
- **Probability**: Low (15%)
- **Impact**: Low - Development delays
- **Technical Mitigation**:
  - Use Docker for consistent development environments
  - Implement clear API contracts between components
  - Regular integration testing throughout development
  - Comprehensive documentation of interfaces
- **Contingency Plan**: Simplify architecture or extend timeline

### 3.3 Scalability Analysis

#### 3.3.1 Current Architecture Scalability

**User Load Capacity**
- **Current Target**: 10-50 concurrent users
- **Bottlenecks**: Single server instance, database connections
- **Scaling Options**: Horizontal scaling with load balancers
- **Cost Implications**: Minimal - free tier sufficient for academic project

**Data Volume Scalability**
- **Current Capacity**: 10,000+ videos, 1M+ snapshots
- **Growth Potential**: 10x growth possible without major changes
- **Storage Scaling**: Database partitioning and archiving strategies
- **Processing Scaling**: Distributed computing for model training

#### 3.3.2 Future Scalability Considerations

**Technical Architecture Evolution**
- **Microservices**: Decompose monolithic application for better scalability
- **Caching Layer**: Redis for improved response times
- **CDN Integration**: Global content delivery for international users
- **Auto-scaling**: Cloud-native scaling based on demand

**Performance Optimization**
- **Model Optimization**: Quantization and pruning for faster inference
- **Database Optimization**: Query optimization and connection pooling
- **Caching Strategy**: Multi-level caching for improved response times
- **Load Balancing**: Distribute traffic across multiple instances

---

## 4. Financial Feasibility

### 4.1 Zero-Cost MVP Implementation Strategy

#### 4.1.1 Comprehensive Cost Analysis

**Development Costs: $0**
- **Team Labor**: Student project - no monetary cost
- **Development Tools**: Free and open-source software stack
- **Learning Resources**: Free online documentation and tutorials
- **Hardware**: Existing team laptops sufficient for development

**Infrastructure Costs: $0**
- **Cloud Hosting**: Heroku free tier (512MB RAM, 1 dyno)
- **Database**: Heroku Postgres free tier (10,000 rows, 1GB storage)
- **Domain**: Free subdomain (viewtrendssl.herokuapp.com)
- **SSL Certificate**: Included with Heroku hosting
- **Monitoring**: Basic logging included in free tier

**API and Service Costs: $0**
- **YouTube Data API**: 30,000 units/day across 3 keys (sufficient for MVP)
- **Version Control**: GitHub free tier for public repositories
- **CI/CD**: GitHub Actions free tier (2,000 minutes/month)
- **Documentation**: GitHub Pages for project documentation

#### 4.1.2 Resource Investment Analysis

**Human Resource Investment**
- **Total Project Hours**: 360 person-hours (3 people Ã— 10 hours/week Ã— 12 weeks)
- **Skill Development Value**: $15,000+ equivalent in professional training
- **Academic Credit**: 3 credit hours per team member
- **Portfolio Value**: Significant enhancement to professional portfolios

**Opportunity Cost Analysis**
- **Alternative Activities**: Part-time work, other coursework, personal projects
- **Expected Return**: Academic achievement, skill development, career advancement
- **Risk-Adjusted Value**: High - low financial risk with significant learning potential
- **Long-term Benefits**: Industry connections, research experience, technical expertise

### 4.2 Budget Constraints and Limitations

#### 4.2.1 Free Tier Limitations

**Heroku Free Tier Constraints**
- **Dyno Hours**: 550 hours/month (sufficient for development and testing)
- **Memory**: 512MB RAM (adequate for MVP but may limit concurrent users)
- **Storage**: 1GB database storage (sufficient for expected data volume)
- **Bandwidth**: No explicit limits but performance throttling possible

**Mitigation Strategies**
- **Efficient Resource Usage**: Optimize code and database queries
- **Caching Implementation**: Reduce server load through intelligent caching
- **Monitoring**: Track resource usage to prevent service interruptions
- **Backup Plans**: Alternative free hosting options identified

#### 4.2.2 Scaling Cost Projections

**Post-MVP Scaling Costs (Future Consideration)**
- **Heroku Standard Dyno**: $25/month for improved performance
- **Database Upgrade**: $50/month for increased storage and connections
- **CDN Services**: $10-20/month for global content delivery
- **Monitoring Tools**: $20/month for advanced analytics

**Revenue Potential (Future)**
- **Freemium Model**: Free basic features, premium analytics ($10-50/month)
- **API Access**: Developer tier ($100-500/month for businesses)
- **Consulting Services**: Custom analytics and insights ($1000+/project)
- **Data Licensing**: Anonymized dataset licensing to researchers

---

## 5. Operational Feasibility

### 5.1 Team Capability Assessment

#### 5.1.1 Technical Skills Analysis

**Senevirathne S.M.P.U. - Data Lead**
- **Strengths**: YouTube domain expertise, data analysis experience
- **Technical Skills**: Python, data preprocessing, statistical analysis
- **Learning Requirements**: YouTube API integration, advanced data validation
- **Capacity**: 10-12 hours/week, high motivation for data-driven insights
- **Risk Factors**: Limited experience with large-scale data collection

**Sanjula N.G.K. - Backend & Model Lead**
- **Strengths**: Strong programming background, ML experience
- **Technical Skills**: Python, machine learning, web development
- **Learning Requirements**: XGBoost optimization, Flask deployment
- **Capacity**: 10-12 hours/week, strong technical problem-solving skills
- **Risk Factors**: Limited experience with production ML systems

**Shaamma M.S. - Frontend & Documentation Lead**
- **Strengths**: Documentation skills, user experience focus
- **Technical Skills**: Web development, data visualization, technical writing
- **Learning Requirements**: Streamlit advanced features, interactive visualizations
- **Capacity**: 10-12 hours/week, strong attention to detail
- **Risk Factors**: Limited experience with complex data visualization

#### 5.1.2 Team Collaboration Framework

**Communication Structure**
- **Regular Meetings**: Twice weekly (Monday planning, Friday review)
- **Daily Updates**: Brief progress reports via team chat
- **Documentation**: Shared Google Drive and GitHub wiki
- **Code Reviews**: All major changes require peer review
- **Conflict Resolution**: Escalation to project mentor if needed

**Development Workflow**
- **Version Control**: Git with feature branch workflow
- **Task Management**: GitHub Projects for issue tracking
- **Code Standards**: PEP-8 compliance with automated linting
- **Testing**: Unit tests for critical functions
- **Integration**: Weekly integration testing and deployment

### 5.2 Resource Availability

#### 5.2.1 Hardware and Software Resources

**Development Hardware**
- **Team Laptops**: 3 laptops with 16GB RAM, modern processors
- **Backup Options**: University computer labs available
- **Network**: High-speed internet access for all team members
- **Storage**: Cloud storage for data backup and sharing

**Software Resources**
- **Development Tools**: VS Code, Jupyter Lab, Git
- **Cloud Services**: GitHub, Heroku, Google Cloud (for APIs)
- **Communication**: Google Workspace, Slack/Discord
- **Documentation**: Markdown, Google Docs, GitHub Pages

#### 5.2.2 External Support Systems

**Academic Support**
- **Project Mentors**: Regular guidance and feedback sessions
- **University Resources**: Library access, computing facilities
- **Peer Support**: Collaboration with other student projects
- **Faculty Expertise**: Access to ML and web development experts

**Community Support**
- **Online Communities**: Stack Overflow, Reddit, GitHub
- **Documentation**: Extensive online resources for all technologies
- **Tutorials**: Free courses and tutorials for skill development
- **Open Source**: Large community of contributors and maintainers

### 5.3 Timeline Feasibility

#### 5.3.1 Critical Path Analysis

**Week 1-2: Foundation Phase**
- **Critical Tasks**: Environment setup, API integration, team coordination
- **Dependencies**: API key approval, development environment consistency
- **Risk Factors**: Learning curve for new technologies
- **Mitigation**: Early start, comprehensive documentation

**Week 3-4: Data Collection Phase**
- **Critical Tasks**: Data pipeline implementation, channel identification
- **Dependencies**: API quota management, data quality validation
- **Risk Factors**: API limitations, data availability
- **Mitigation**: Multiple API keys, efficient usage patterns

**Week 5-6: Model Development Phase**
- **Critical Tasks**: Feature engineering, model training, evaluation
- **Dependencies**: Clean dataset availability, computational resources
- **Risk Factors**: Model performance, overfitting
- **Mitigation**: Baseline models, cross-validation, feature selection

**Week 7-8: Integration Phase**
- **Critical Tasks**: System integration, testing, optimization
- **Dependencies**: Component completion, interface definitions
- **Risk Factors**: Integration complexity, performance issues
- **Mitigation**: Incremental integration, comprehensive testing

**Week 9-10: Deployment Phase**
- **Critical Tasks**: Production deployment, documentation, presentation
- **Dependencies**: System stability, comprehensive testing
- **Risk Factors**: Deployment issues, last-minute bugs
- **Mitigation**: Early deployment testing, backup plans

#### 5.3.2 Resource Allocation Strategy

**Parallel Development Approach**
- **Weeks 3-4**: Data collection (Senevirathne) + Database design (Sanjula) + UI mockups (Shaamma)
- **Weeks 5-6**: Model development (Sanjula) + Data analysis (Senevirathne) + Frontend development (Shaamma)
- **Weeks 7-8**: Integration testing (All) + Documentation (Shaamma) + Optimization (Sanjula)
- **Weeks 9-10**: Deployment (Sanjula) + Final documentation (Shaamma) + Presentation prep (All)

---

## 6. Risk Assessment

### 6.1 Comprehensive Risk Analysis

#### 6.1.1 Technical Risks

**High-Impact Technical Risks**

**Risk T1: YouTube API Quota Exhaustion**
- **Probability**: High (70%)
- **Impact**: Critical (Project-stopping)
- **Description**: Daily API limits insufficient for data collection needs
- **Quantified Impact**: Could delay data collection by 2-4 weeks
- **Mitigation Strategy**:
  - Use 3 team member API keys (30,000 units/day total)
  - Implement efficient API call patterns
  - Cache responses to prevent redundant calls
  - Monitor usage with automated alerts
- **Contingency Plan**: Social Blade API integration, manual data collection

**Risk T2: Model Performance Below Threshold**
- **Probability**: Medium (40%)
- **Impact**: High (Core functionality compromised)
- **Description**: ML models fail to achieve MAPE < 30% target
- **Quantified Impact**: Reduced project value, potential scope adjustment
- **Mitigation Strategy**:
  - Start with baseline models for comparison
  - Focus on feature engineering over algorithm complexity
  - Use ensemble methods and cross-validation
  - Regular performance monitoring and adjustment
- **Contingency Plan**: Adjust success criteria, focus on specific categories

#### 6.1.2 Operational Risks

**Risk O1: Team Coordination Challenges**
- **Probability**: Medium (30%)
- **Impact**: Medium (Timeline delays)
- **Description**: Different environments and schedules cause integration issues
- **Quantified Impact**: 1-2 week delays in integration phase
- **Mitigation Strategy**:
  - Docker for consistent environments
  - Regular communication and meetings
  - Clear role definitions and responsibilities
  - Shared documentation and code standards
- **Contingency Plan**: Increased meeting frequency, mentor intervention

**Risk O2: Scope Creep**
- **Probability**: Medium (35%)
- **Impact**: Medium (Timeline and quality impact)
- **Description**: Team attempts too many features, compromising MVP
- **Quantified Impact**: Incomplete core features, rushed implementation
- **Mitigation Strategy**:
  - Strict MVP definition and feature prioritization
  - Regular scope review meetings
  - "MVP/V2/Backlog" categorization system
  - Strong project management discipline
- **Contingency Plan**: Feature freeze, focus on core functionality

#### 6.1.3 External Risks

**Risk E1: API Terms of Service Changes**
- **Probability**: Low (10%)
- **Impact**: High (Legal and technical complications)
- **Description**: YouTube changes API terms affecting project legality
- **Quantified Impact**: Potential project restructuring or termination
- **Mitigation Strategy**:
  - Regular monitoring of API announcements
  - Compliance documentation and legal review
  - Alternative data source identification
  - Academic use case documentation
- **Contingency Plan**: Pivot to alternative data sources or synthetic data

### 6.2 Risk Mitigation Framework

#### 6.2.1 Risk Monitoring System

**Weekly Risk Assessment**
- **Risk Status Review**: Evaluate probability and impact changes
- **Mitigation Effectiveness**: Assess current mitigation strategies
- **New Risk Identification**: Identify emerging risks
- **Action Plan Updates**: Adjust mitigation strategies as needed

**Risk Indicators and Triggers**
- **API Usage**: >80% daily quota utilization
- **Model Performance**: MAPE >40% in validation
- **Timeline Adherence**: >1 week behind schedule
- **Team Coordination**: Missed meetings or deliverables

#### 6.2.2 Contingency Planning

**Scenario Planning**
- **Best Case**: All systems work perfectly, ahead of schedule
- **Expected Case**: Minor issues resolved through mitigation
- **Worst Case**: Major technical failures requiring scope adjustment
- **Crisis Case**: Project-threatening issues requiring mentor intervention

**Resource Reallocation Plans**
- **Technical Issues**: Redistribute tasks based on expertise
- **Timeline Pressure**: Prioritize core features, defer nice-to-haves
- **Team Issues**: Mentor mediation and role adjustment
- **External Issues**: Pivot strategies and alternative approaches

---

## 7. Legal and Compliance Analysis

### 7.1 Regulatory Compliance

#### 7.1.1 YouTube API Terms of Service Compliance

**Key Compliance Requirements**
- **Attribution**: Proper attribution to YouTube for data source
- **Data Usage**: Analytics and research use explicitly permitted
- **Rate Limiting**: Respect API quotas and rate limits
- **Data Retention**: No long-term storage of raw API responses
- **User Privacy**: No collection of private user information

**Compliance Implementation**
- **Legal Review**: Thorough review of current ToS (updated regularly)
- **Attribution Implementation**: Clear YouTube attribution in application
- **Data Handling**: Processed data storage, not raw API responses
- **Privacy Protection**: No personal user data collection
- **Documentation**: Compliance documentation for audit purposes

#### 7.1.2 Academic Ethics and Research Standards

**University Ethics Requirements**
- **Research Ethics**: Compliance with university research guidelines
- **Data Protection**: Appropriate handling of public data
- **Academic Integrity**: Original work with proper citations
- **Collaboration**: Appropriate team collaboration and attribution

**Implementation Strategy**
- **Ethics Review**: Consultation with university ethics committee if required
- **Documentation**: Comprehensive methodology documentation
- **Citation Standards**: Proper academic citation of sources and methods
- **Transparency**: Open-source approach with transparent algorithms

### 7.2 Data Protection and Privacy

#### 7.2.1 Data Handling Policies

**Data Collection Principles**
- **Public Data Only**: Exclusively public YouTube video metadata
- **No Personal Information**: No collection of user comments or personal data
- **Aggregated Analysis**: Focus on patterns rather than individual behavior
- **Anonymization**: Remove or hash identifying information where possible

**Data Storage and Security**
- **Secure Storage**: Encrypted database storage
- **Access Control**: Limited access to team members only
- **Backup Security**: Encrypted backups with access controls
- **Data Retention**: Clear policies for data retention and deletion

#### 7.2.2 User Privacy Protection

**Application Privacy Measures**
- **Minimal Data Collection**: Only essential user information (email for login)
- **Password Security**: Bcrypt hashing for password storage
- **Session Management**: Secure session handling and timeout
- **Privacy Policy**: Clear privacy policy explaining data usage

**Transparency and Control**
- **Data Usage Disclosure**: Clear explanation of how data is used
- **User Rights**: Right to account deletion and data removal
- **Opt-out Options**: Ability to limit data usage
- **Contact Information**: Clear contact for privacy concerns

### 7.3 Intellectual Property Considerations

#### 7.3.1 Open Source Strategy

**Licensing Approach**
- **MIT License**: Permissive license allowing commercial use
- **Code Availability**: Full source code available on GitHub
- **Documentation**: Comprehensive documentation for reproducibility
- **Community Contribution**: Welcoming community contributions

**IP Protection**
- **Original Work**: All code and algorithms developed by team
- **Third-party Libraries**: Proper attribution and license compliance
- **Research Attribution**: Proper citation of academic sources
- **University Rights**: Compliance with university IP policies

#### 7.3.2 Commercial Considerations

**Future Commercialization**
- **Business Model**: Freemium approach with premium features
- **IP Ownership**: Clear ownership structure for future development
- **Partnership Opportunities**: Potential industry partnerships
- **Academic Collaboration**: Ongoing research collaboration opportunities

---

## 8. Success Criteria and Evaluation

### 8.1 Quantitative Success Metrics

#### 8.1.1 Technical Performance Metrics

**Model Accuracy Targets**
- **Primary Target**: MAPE < 30% for 7-day view predictions
- **Secondary Targets**: 
  - MAE < 5,000 views for videos with <50K expected views
  - RÂ² Score > 0.6 for overall model performance
  - Separate evaluation for Shorts vs Long-form content

**System Performance Targets**
- **Response Time**: 95% of predictions delivered within 30 seconds
- **Availability**: 95% uptime during evaluation period
- **Scalability**: Support 10+ concurrent users without degradation
- **Data Processing**: Process 1,000+ videos per hour during collection

#### 8.1.2 Data Quality Metrics

**Dataset Completeness**
- **Channel Coverage**: 100+ Sri Lankan channels across categories
- **Video Volume**: 5,000+ videos in training dataset
- **Temporal Coverage**: 6+ months of historical data
- **Data Accuracy**: <5% missing values in critical fields

**Feature Engineering Success**
- **Feature Importance**: Clear ranking of predictive features
- **Feature Stability**: Consistent performance across time periods
- **Domain Relevance**: Features align with YouTube algorithm factors
- **Correlation Analysis**: Optimal balance of informative vs redundant features

### 8.2 Qualitative Success Metrics

#### 8.2.1 Academic Excellence

**Documentation Quality**
- **Comprehensive Coverage**: All aspects of project thoroughly documented
- **Technical Accuracy**: Accurate technical descriptions and methodologies
- **Reproducibility**: Sufficient detail for project reproduction
- **Academic Standards**: Meets university documentation requirements

**Research Contribution**
- **Novel Approach**: Innovative methodology for regional viewership prediction
- **Academic Value**: Contribution to social media analytics research
- **Open Source Impact**: Community adoption and contribution potential
- **Publication Potential**: Quality suitable for academic conference submission

#### 8.2.2 Practical Impact

**User Experience Quality**
- **Intuitive Interface**: Easy to use without technical training
- **Valuable Insights**: Actionable predictions for content creators
- **Reliable Performance**: Consistent and dependable results
- **Professional Presentation**: Polished, production-ready appearance

**Industry Relevance**
- **Real-world Applicability**: Practical value for Sri Lankan creators
- **Market Validation**: Positive feedback from target users
- **Competitive Advantage**: Clear differentiation from existing tools
- **Scalability Potential**: Architecture supports future growth

### 8.3 Evaluation Framework

#### 8.3.1 Testing Methodology

**Model Evaluation Protocol**
1. **Cross-Validation**: 5-fold cross-validation for robust estimates
2. **Temporal Validation**: Test on future data to simulate real usage
3. **Category Analysis**: Performance evaluation across content types
4. **Baseline Comparison**: Compare against simple heuristic models

**System Testing Protocol**
1. **Functional Testing**: Verify all features work as specified
2. **Performance Testing**: Validate response times and scalability
3. **Integration Testing**: Ensure seamless component interaction
4. **User Acceptance Testing**: Real-world scenarios with stakeholders

#### 8.3.2 Success Thresholds

**Minimum Viable Product Thresholds**
- **Model Performance**: MAPE < 35% (adjusted for academic project constraints)
- **System Reliability**: 90% of predictions successful within time limits
- **User Experience**: 85% task completion rate for core features
- **Documentation**: Complete documentation meeting academic standards

**Excellence Thresholds**
- **Model Performance**: MAPE < 25% with high confidence intervals
- **Advanced Features**: Implementation of 2+ future roadmap features
- **Research Impact**: Submission to academic conference or journal
- **Community Adoption**: 50+ external users during beta testing

---

## 9. Recommendations

### 9.1 Project Approval Recommendation

#### 9.1.1 Overall Assessment

**Feasibility Verdict: PROCEED WITH CONFIDENCE**

Based on comprehensive analysis across technical, financial, operational, and legal dimensions, ViewTrendsSL demonstrates strong feasibility for successful completion within the 10-week academic timeline. The project leverages proven technologies, requires zero financial investment, and addresses a genuine market need with clear academic value.

**Key Strengths Supporting Approval:**
1. **Technical Viability**: Proven ML algorithms and established web technologies
2. **Zero Financial Risk**: Complete implementation using free-tier services
3. **Clear Market Need**: Identified gap in regional YouTube analytics tools
4. **Strong Team Capability**: Complementary skills and clear role allocation
5. **Academic Value**: Research contribution with publication potential

#### 9.1.2 Critical Success Factors

**Essential Requirements for Success:**
1. **Strict Scope Management**: Maintain focus on MVP features
2. **Early Risk Mitigation**: Implement API quota management immediately
3. **Regular Progress Monitoring**: Weekly milestone reviews and adjustments
4. **Quality Assurance**: Comprehensive testing throughout development
5. **Documentation Excellence**: Maintain high documentation standards

### 9.2 Implementation Recommendations

#### 9.2.1 Immediate Action Items (Week 1)

**High Priority Setup Tasks:**
1. **API Key Management**: Secure 3 YouTube API keys and implement quota monitoring
2. **Development Environment**: Set up Docker containers for consistent environments
3. **Project Infrastructure**: Initialize GitHub repository with proper structure
4. **Team Coordination**: Establish communication channels and meeting schedules
5. **Risk Monitoring**: Implement risk tracking and mitigation systems

**Technical Foundation Tasks:**
1. **Database Design**: Implement core schema for channels, videos, and snapshots
2. **API Integration**: Create basic YouTube API wrapper with error handling
3. **Data Validation**: Implement data quality checks and validation pipelines
4. **Testing Framework**: Set up unit testing and continuous integration
5. **Documentation System**: Establish documentation standards and templates

#### 9.2.2 Risk Mitigation Priorities

**Critical Risk Mitigation (Weeks 1-2):**
1. **API Quota Optimization**: Implement efficient API usage patterns
2. **Team Coordination**: Establish clear workflows and communication protocols
3. **Scope Definition**: Create detailed MVP specification with feature prioritization
4. **Technical Validation**: Proof-of-concept for core technical components
5. **Backup Planning**: Identify alternative approaches for high-risk components

**Ongoing Risk Management:**
1. **Weekly Risk Reviews**: Regular assessment of risk status and mitigation effectiveness
2. **Performance Monitoring**: Continuous tracking of technical and project metrics
3. **Stakeholder Communication**: Regular updates to mentors and stakeholders
4. **Contingency Activation**: Clear triggers for implementing backup plans
5. **Quality Gates**: Milestone-based quality checks and go/no-go decisions

### 9.3 Long-term Strategic Recommendations

#### 9.3.1 Post-Project Development Path

**Phase 1: Academic Completion (Weeks 9-10)**
- Focus on successful project completion and presentation
- Ensure all academic requirements are met with high quality
- Prepare comprehensive documentation for future development
- Establish foundation for potential research publication

**Phase 2: Community Validation (Months 1-3 post-project)**
- Deploy beta version for Sri Lankan creator community testing
- Collect user feedback and usage analytics
- Refine model performance based on real-world usage
- Build community around open-source project

**Phase 3: Feature Enhancement (Months 3-6 post-project)**
- Implement advanced features based on user feedback
- Expand to additional content categories and prediction horizons
- Develop premium features for potential monetization
- Establish partnerships with creator economy organizations

#### 9.3.2 Research and Publication Strategy

**Academic Contribution Path:**
1. **Conference Submission**: Target regional computer science conferences
2. **Journal Publication**: Prepare comprehensive research paper
3. **Dataset Release**: Publish anonymized dataset for research community
4. **Open Source Maintenance**: Establish sustainable open-source project

**Industry Engagement:**
1. **Creator Community**: Build relationships with Sri Lankan YouTube creators
2. **Academic Partnerships**: Collaborate with other universities on regional studies
3. **Industry Connections**: Engage with digital marketing and media companies
4. **Government Relations**: Explore support for digital economy initiatives

---

## 10. References

### 10.1 Academic References

#### 10.1.1 Primary Research Sources

1. **Zhang, Y., et al. (2024)**. "AMPS: Predicting popularity of short-form videos using multi-modal attention mechanisms." *Journal of Retailing and Consumer Services*, 78, 103742.
   - DOI: https://doi.org/10.1016/j.jretconser.2024.103742
   - **Relevance**: Validates separate model approach for Shorts vs Long-form videos

2. **Liu, X., et al. (2025)**. "SMTPD: A New Benchmark for Temporal Prediction of Social Media Popularity." *arXiv preprint arXiv:2503.04446*.
   - URL: https://arxiv.org/html/2503.04446v1
   - **Relevance**: Temporal prediction framework and early engagement importance

3. **Chen, T., & Guestrin, C. (2016)**. "XGBoost: A scalable tree boosting system." *Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining*, 785-794.
   - **Relevance**: Technical foundation for chosen ML algorithm

#### 10.1.2 Supporting Literature

4. **Bakshy, E., et al. (2012)**. "The role of social networks in information diffusion." *Proceedings of the 21st International Conference on World Wide Web*, 519-528.
   - **Relevance**: Social media information diffusion patterns

5. **Crane, R., & Dempsey, D. (2018)**. "Edge of chaos: Social media and the prediction of viral content." *Physical Review E*, 98(1), 012323.
   - **Relevance**: Theoretical foundation for viral content prediction

### 10.2 Technical Documentation

#### 10.2.1 API and Service Documentation

1. **Google Developers (2024)**. "YouTube Data API v3 - Getting Started."
   - URL: https://developers.google.com/youtube/v3/getting-started
   - **Usage**: Primary API documentation and implementation guide

2. **YouTube API Services Terms of Service (2024)**. Google LLC.
   - URL: https://developers.google.com/youtube/terms/api-services-terms-of-service
   - **Usage**: Legal compliance and terms of service requirements

#### 10.2.2 Technology Stack Documentation

3. **XGBoost Documentation (2024)**. XGBoost Contributors.
   - URL: https://xgboost.readthedocs.io/
   - **Usage**: Machine learning implementation and optimization

4. **Flask Documentation (2024)**. Pallets Projects.
   - URL: https://flask.palletsprojects.com/
   - **Usage**: Web application framework implementation

5. **Streamlit Documentation (2024)**. Streamlit Inc.
   - URL: https://docs.streamlit.io/
   - **Usage**: Frontend development and data visualization

### 10.3 Market Research Sources

#### 10.3.1 Industry Reports

1. **DataReportal (2024)**. "Digital 2024: Sri Lanka - The Essential Guide to Digital Trends."
   - **Usage**: Market size and digital adoption statistics

2. **We Are Social & Kepios (2024)**. "Digital 2024 Global Overview Report."
   - **Usage**: Global social media trends and regional comparisons

#### 10.3.2 Competitive Analysis Sources

3. **VidIQ Official Website (2024)**. VidIQ LLC.
   - URL: https://vidiq.com/
   - **Usage**: Competitive feature analysis and market positioning

4. **Social Blade Official Website (2024)**. Social Blade LLC.
   - URL: https://socialblade.com/
   - **Usage**: Competitive analysis and market gap identification

### 10.4 Regulatory and Compliance Sources

#### 10.4.1 Legal and Regulatory Framework

1. **University of Moratuwa Research Ethics Guidelines (2024)**. University of Moratuwa.
   - **Usage**: Academic ethics compliance and research standards

2. **Sri Lanka Data Protection Act (2022)**. Parliament of Sri Lanka.
   - **Usage**: Local data protection compliance requirements

#### 10.4.2 Best Practices and Standards

3. **IEEE Standards for Software Engineering (2024)**. IEEE Computer Society.
   - **Usage**: Software development standards and best practices

4. **ACM Code of Ethics and Professional Conduct (2018)**. Association for Computing Machinery.
   - **Usage**: Professional ethics and conduct guidelines

---

## Appendices

### Appendix A: Risk Register Template

| Risk ID | Category | Description | Probability | Impact | Risk Score | Mitigation Strategy | Owner | Status |
|---------|----------|-------------|-------------|---------|------------|-------------------|-------|---------|
| T1 | Technical | API Quota Exhaustion | High | Critical | 9 | Multi-key strategy | Data Lead | Active |
| T2 | Technical | Model Performance | Medium | High | 6 | Baseline comparison | Model Lead | Monitoring |
| O1 | Operational | Team Coordination | Medium | Medium | 4 | Docker + Communication | All | Active |

### Appendix B: Success Metrics Dashboard Template

| Metric Category | Metric | Target | Current | Status | Trend |
|----------------|---------|---------|---------|---------|-------|
| Model Performance | MAPE (7-day) | <30% | TBD | Pending | - |
| System Performance | Response Time | <30s | TBD | Pending | - |
| Data Quality | Missing Values | <5% | TBD | Pending | - |

### Appendix C: Compliance Checklist

- [ ] YouTube API Terms of Service reviewed and documented
- [ ] University ethics guidelines compliance verified
- [ ] Data protection measures implemented
- [ ] Privacy policy created and published
- [ ] Open source licensing strategy defined
- [ ] Academic integrity standards maintained

---

**Document Control**
- **Version**: 1.0
- **Last Updated**: August 6, 2025
- **Next Review**: August 13, 2025
- **Approved By**: [To be completed by project mentor]
- **Distribution**: Project team, university mentors, academic supervisors

*This feasibility study provides the foundation for project approval and serves as a reference document throughout the project lifecycle. Regular updates will be made to reflect changing conditions and new insights.*
